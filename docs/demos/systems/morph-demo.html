<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neuron Morph - Input/Output Transformation Demo</title>
		<!-- FAVICON CODE -->
	<link rel="icon" type="image/svg+xml" href="../../logo/favicon.svg">
    <link rel="stylesheet" href="../../css/navigation.css">
    <style>
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #3a1d1d 0%, #5c2c1a 50%, #6d4b1a 100%);
            min-height: 100vh;
            padding: 16px;
            padding-top: 90px !important;
            overflow-x: hidden;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
        }

        /* Header */
        .header {
            text-align: center;
            margin-bottom: 32px;
            color: white;
        }

        .header h1 {
            font-size: 32px;
            font-weight: 700;
            margin: 0 0 8px 0;
            text-shadow: 0 2px 4px rgba(0,0,0,0.5);
            background: linear-gradient(135deg, #ef4444, #dc2626);
            background-clip: text;
        }

        .header p {
            font-size: 18px;
            opacity: 0.9;
            color: #fecaca;
        }

        /* Main Demo Layout */
        .demo-layout {
            display: grid;
            grid-template-columns: 380px 1fr;
            gap: 24px;
            margin-bottom: 32px;
        }

        @media (max-width: 1400px) {
            .demo-layout {
                grid-template-columns: 1fr;
            }
        }

        /* Control Panel */
        .control-panel {
            background: rgba(58, 29, 29, 0.6);
            border-radius: 20px;
            padding: 24px;
            backdrop-filter: blur(15px);
            border: 1px solid rgba(239, 68, 68, 0.3);
            height: fit-content;
        }

        .control-title {
            color: #ef4444;
            font-size: 18px;
            font-weight: 600;
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        /* Input Sources */
        .input-section {
            margin-bottom: 24px;
        }

        .input-label {
            color: rgba(254, 202, 202, 0.9);
            font-size: 14px;
            font-weight: 600;
            margin-bottom: 12px;
        }

        .input-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 8px;
            margin-bottom: 16px;
        }

        .input-source {
            background: rgba(58, 29, 29, 0.5);
            border: 1px solid rgba(239, 68, 68, 0.5);
            color: white;
            padding: 12px;
            border-radius: 12px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 11px;
            text-align: center;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 4px;
        }

        .input-source:hover {
            background: rgba(239, 68, 68, 0.2);
            border-color: rgba(239, 68, 68, 0.7);
            transform: translateY(-2px);
        }

        .input-source.active {
            background: rgba(239, 68, 68, 0.4);
            border-color: rgba(239, 68, 68, 0.8);
        }

        .input-icon {
            font-size: 18px;
            margin-bottom: 4px;
        }

        .input-name {
            font-weight: 600;
            font-size: 10px;
        }

        .input-type {
            font-size: 8px;
            opacity: 0.8;
        }

        /* Transformation Mode */
        .transformation-section {
            margin-bottom: 24px;
        }

        .transformation-buttons {
            display: flex;
            flex-direction: column;
            gap: 8px;
        }

        .transformation-button {
            background: rgba(58, 29, 29, 0.5);
            border: 1px solid rgba(239, 68, 68, 0.5);
            color: white;
            padding: 12px 16px;
            border-radius: 12px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 13px;
            text-align: left;
        }

        .transformation-button:hover {
            background: rgba(239, 68, 68, 0.2);
            border-color: rgba(239, 68, 68, 0.7);
        }

        .transformation-button.active {
            background: rgba(239, 68, 68, 0.4);
            border-color: rgba(239, 68, 68, 0.8);
        }

        /* Output Formats */
        .output-section {
            margin-bottom: 24px;
        }

        .output-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 8px;
        }

        .output-format {
            background: rgba(58, 29, 29, 0.5);
            border: 1px solid rgba(239, 68, 68, 0.5);
            color: white;
            padding: 10px;
            border-radius: 12px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 11px;
            text-align: center;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 4px;
        }

        .output-format:hover {
            background: rgba(239, 68, 68, 0.2);
            border-color: rgba(239, 68, 68, 0.7);
        }

        .output-format.active {
            background: rgba(239, 68, 68, 0.4);
            border-color: rgba(239, 68, 68, 0.8);
        }

        .output-icon {
            font-size: 16px;
            margin-bottom: 2px;
        }

        .output-name {
            font-weight: 600;
            font-size: 9px;
        }

        /* System Metrics */
        .metrics-section {
            margin-bottom: 24px;
        }

        .metric-item {
            background: rgba(58, 29, 29, 0.5);
            border-radius: 8px;
            padding: 12px;
            margin-bottom: 12px;
            border-left: 4px solid #ef4444;
        }

        .metric-label {
            color: rgba(254, 202, 202, 0.8);
            font-size: 12px;
            font-weight: 600;
            margin-bottom: 4px;
        }

        .metric-value {
            color: white;
            font-size: 18px;
            font-family: monospace;
            font-weight: 600;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .metric-unit {
            font-size: 12px;
            opacity: 0.8;
        }

        .metric-status {
            font-size: 10px;
            padding: 2px 6px;
            border-radius: 4px;
            font-weight: 500;
            background: rgba(220, 38, 38, 0.2);
            color: #dc2626;
        }

        /* Transformation Display */
        .transformation-display {
            background: rgba(58, 29, 29, 0.4);
            border-radius: 20px;
            padding: 24px;
            backdrop-filter: blur(15px);
            border: 1px solid rgba(239, 68, 68, 0.3);
            position: relative;
        }

        /* Transformation Visualization */
        .transformation-visual {
            background: rgba(0, 0, 0, 0.3);
            border-radius: 16px;
            padding: 20px;
            margin-bottom: 24px;
            border: 2px solid rgba(239, 68, 68, 0.4);
            position: relative;
            min-height: 280px;
            overflow: hidden;
        }

        .transformation-animation {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            font-size: 60px;
            color: #ef4444;
            text-align: center;
        }

        .transformation-icon {
            animation: pulse 2s ease-in-out infinite;
            margin-bottom: 12px;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }

        .transformation-status {
            color: white;
            font-size: 18px;
            font-weight: 600;
            text-align: center;
        }

        .transformation-substatus {
            color: rgba(254, 202, 202, 0.8);
            font-size: 14px;
            margin-top: 8px;
        }

        /* Transformation Pipeline */
        .transformation-pipeline {
            position: absolute;
            bottom: 20px;
            left: 20px;
            right: 20px;
            display: grid;
            grid-template-columns: 1fr auto 1fr auto 1fr;
            gap: 12px;
            align-items: center;
            opacity: 0;
            transition: opacity 0.5s ease;
        }

        .transformation-pipeline.show {
            opacity: 1;
        }

        .pipeline-step {
            background: rgba(0, 0, 0, 0.3);
            border-radius: 8px;
            padding: 8px;
            text-align: center;
        }

        .pipeline-label {
            font-size: 9px;
            color: rgba(254, 202, 202, 0.7);
            margin-bottom: 4px;
        }

        .pipeline-value {
            font-size: 12px;
            font-weight: 600;
            color: #ef4444;
        }

        .pipeline-arrow {
            color: #ef4444;
            font-size: 16px;
            animation: pulse 1s infinite;
        }

        /* Transformation Examples */
        .examples-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 16px;
            margin-bottom: 24px;
            opacity: 0;
            transition: opacity 0.5s ease;
        }

        .examples-grid.show {
            opacity: 1;
        }

        .example-category {
            background: rgba(58, 29, 29, 0.5);
            border-radius: 12px;
            padding: 16px;
            border: 1px solid rgba(239, 68, 68, 0.3);
        }

        .example-header {
            display: flex;
            align-items: center;
            gap: 8px;
            margin-bottom: 12px;
        }

        .example-icon {
            font-size: 18px;
        }

        .example-name {
            color: white;
            font-size: 14px;
            font-weight: 600;
        }

        .example-content {
            color: rgba(254, 202, 202, 0.9);
            font-size: 12px;
            line-height: 1.4;
        }

        /* Real-time Processing */
        .processing-status {
            background: rgba(58, 29, 29, 0.5);
            border-radius: 12px;
            padding: 16px;
            border-left: 4px solid #ef4444;
            opacity: 0;
            transition: opacity 0.5s ease;
        }

        .processing-status.show {
            opacity: 1;
        }

        .processing-header {
            color: #ef4444;
            font-size: 16px;
            font-weight: 600;
            margin-bottom: 12px;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .processing-content {
            color: rgba(254, 202, 202, 0.9);
            font-size: 14px;
            line-height: 1.5;
        }

        /* Process Buttons */
        .process-buttons {
            display: flex;
            gap: 12px;
            margin-bottom: 16px;
        }

        .process-button {
            background: linear-gradient(135deg, #b91c1c, #991b1b);
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 12px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            flex: 1;
        }

        .process-button:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(185, 28, 28, 0.4);
        }

        .process-button:disabled {
            background: rgba(75, 85, 99, 0.5);
            color: #9ca3af;
            cursor: not-allowed;
            transform: none;
        }

        .transform-button {
            background: linear-gradient(135deg, #ef4444, #dc2626);
        }

        /* Simulation Message */
        .simulation-message {
            background: rgba(239, 68, 68, 0.1);
            border: 1px solid rgba(239, 68, 68, 0.3);
            border-radius: 8px;
            padding: 12px;
            margin-top: 16px;
            color: #ef4444;
            font-size: 14px;
            text-align: center;
            display: none;
        }

        /* Comparison Section */
        .comparison-section {
            background: rgba(58, 29, 29, 0.4);
            border-radius: 20px;
            padding: 24px;
            margin-top: 24px;
            backdrop-filter: blur(15px);
            border: 1px solid rgba(239, 68, 68, 0.3);
        }

        .comparison-title {
            color: white;
            font-size: 20px;
            font-weight: 600;
            text-align: center;
            margin-bottom: 24px;
        }

        .comparison-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 24px;
        }

        @media (max-width: 768px) {
            .comparison-grid {
                grid-template-columns: 1fr;
            }
        }

        .comparison-item {
            background: rgba(58, 29, 29, 0.5);
            border-radius: 12px;
            padding: 20px;
            border: 2px solid;
        }

        .traditional-transformation {
            border-color: #ef4444;
        }

        .neuron-morph {
            border-color: #ef4444;
        }

        .comparison-item h4 {
            margin-bottom: 16px;
            font-size: 16px;
            font-weight: 600;
            color: white;
        }

        .comparison-list {
            list-style: none;
            margin: 0;
        }

        .comparison-list li {
            margin-bottom: 8px;
            position: relative;
            padding-left: 16px;
            font-size: 14px;
            line-height: 1.4;
            color: rgba(254, 202, 202, 0.9);
        }

        .comparison-list li::before {
            content: "‚Ä¢";
            position: absolute;
            left: 0;
            font-weight: bold;
        }

        .traditional-transformation .comparison-list li::before {
            color: #ef4444;
        }

        .neuron-morph .comparison-list li::before {
            color: #ef4444;
        }
		
        /* Action Buttons */
        .action-section {
            text-align: center;
            margin-top: 3rem;
        }

        .action-button {
            display: flex;
            justify-content: center;
            gap: 1.5rem;
            flex-wrap: wrap;
        }

        .action-button {
            display: inline-flex;
            align-items: center;
            gap: 0.75rem;
            padding: 1rem 2rem;
            text-decoration: none;
            border-radius: 12px;
            font-weight: 600;
            font-size: 1rem;
            transition: all 0.3s ease;
            min-width: 200px;
            justify-content: center;
        }
		
		.demo-button {
            background: linear-gradient(135deg, #3b82f6, #1d4ed8);
            color: white;
            box-shadow: 0 4px 15px rgba(59, 130, 246, 0.3);
        }

        .demo-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(59, 130, 246, 0.4);
        }

        .docs-button {
            background: rgba(255, 255, 255, 0.1);
            color: #e2e8f0;
            border: 1px solid rgba(226, 232, 240, 0.2);
        }

        .docs-button:hover {
            background: rgba(255, 255, 255, 0.15);
            transform: translateY(-2px);
        }
		
    </style>
</head>
<body>
    <!-- Navigation -->
    <div>
        <div id="navigation-placeholder"></div>
    </div>

    <div class="container">
        <!-- Header -->
        <div class="header">
            <h1>üîÑ Neuron Morph</h1>
            <p>Input/Output transformation system enabling seamless communication across all media types and interaction modalities</p>
        </div>

        <!-- Main Demo Layout -->
        <div class="demo-layout">
            <!-- Control Panel -->
            <div class="control-panel">
                <div class="control-title">
                    ‚öôÔ∏è Transformation Engine
                </div>

                <!-- Input Sources -->
                <div class="input-section">
                    <div class="input-label">Input Sources:</div>
                    <div class="input-grid">
                        <div class="input-source active" data-input="audio">
                            <div class="input-icon">üé§</div>
                            <div class="input-name">Audio</div>
                            <div class="input-type">Speech/Sound</div>
                        </div>
                        <div class="input-source" data-input="visual">
                            <div class="input-icon">üëÅÔ∏è</div>
                            <div class="input-name">Visual</div>
                            <div class="input-type">Camera/Image</div>
                        </div>
                        <div class="input-source" data-input="text">
                            <div class="input-icon">üìù</div>
                            <div class="input-name">Text</div>
                            <div class="input-type">Keyboard/Chat</div>
                        </div>
                        <div class="input-source" data-input="touch">
                            <div class="input-icon">‚úã</div>
                            <div class="input-name">Touch</div>
                            <div class="input-type">Sensors/Haptic</div>
                        </div>
                        <div class="input-source" data-input="gesture">
                            <div class="input-icon">üëã</div>
                            <div class="input-name">Gesture</div>
                            <div class="input-type">Motion/Body</div>
                        </div>
                        <div class="input-source" data-input="environmental">
                            <div class="input-icon">üå°Ô∏è</div>
                            <div class="input-name">Environment</div>
                            <div class="input-type">Context/Data</div>
                        </div>
                    </div>
                </div>

                <!-- Transformation Mode -->
                <div class="transformation-section">
                    <div class="input-label">Transformation Mode:</div>
                    <div class="transformation-buttons">
                        <div class="transformation-button active" data-mode="realtime">
                            ‚ö° Real-time Processing - Instant transformation
                        </div>
                        <div class="transformation-button" data-mode="contextual">
                            üß† Contextual Adaptation - Situation-aware conversion
                        </div>
                        <div class="transformation-button" data-mode="multimodal">
                            üîÄ Multi-modal Fusion - Combined input processing
                        </div>
                        <div class="transformation-button" data-mode="personalized">
                            üë§ Personalized Style - User-adapted communication
                        </div>
                    </div>
                </div>

                <!-- Output Formats -->
                <div class="output-section">
                    <div class="input-label">Output Formats:</div>
                    <div class="output-grid">
                        <div class="output-format active" data-output="speech">
                            <div class="output-icon">üîä</div>
                            <div class="output-name">Speech</div>
                        </div>
                        <div class="output-format" data-output="visual">
                            <div class="output-icon">üì∫</div>
                            <div class="output-name">Visual</div>
                        </div>
                        <div class="output-format" data-output="text">
                            <div class="output-icon">üí¨</div>
                            <div class="output-name">Text</div>
                        </div>
                        <div class="output-format" data-output="gesture">
                            <div class="output-icon">ü§ñ</div>
                            <div class="output-name">Gesture</div>
                        </div>
                        <div class="output-format" data-output="haptic">
                            <div class="output-icon">üì≥</div>
                            <div class="output-name">Haptic</div>
                        </div>
                        <div class="output-format" data-output="emotional">
                            <div class="output-icon">üòä</div>
                            <div class="output-name">Emotional</div>
                        </div>
                    </div>
                </div>

                <!-- System Metrics -->
                <div class="metrics-section">
                    <div class="input-label">Processing Metrics:</div>
                    
                    <div class="metric-item">
                        <div class="metric-label">Processing Speed</div>
                        <div class="metric-value" id="processingSpeed">
                            15<span class="metric-unit">ms</span>
                            <span class="metric-status">Real-time</span>
                        </div>
                    </div>

                    <div class="metric-item">
                        <div class="metric-label">Accuracy Rate</div>
                        <div class="metric-value" id="accuracyRate">
                            96<span class="metric-unit">%</span>
                            <span class="metric-status">High</span>
                        </div>
                    </div>

                    <div class="metric-item">
                        <div class="metric-label">Active Channels</div>
                        <div class="metric-value" id="activeChannels">
                            6<span class="metric-unit">inputs</span>
                            <span class="metric-status">Multi-modal</span>
                        </div>
                    </div>
                </div>

                <div class="process-buttons">
                    <button class="process-button transform-button" id="startTransformation">Start Transformation</button>
                    <button class="process-button" id="demonstrateAdaptation">Show Adaptation</button>
                </div>

                <div id="simulationMessage" class="simulation-message">
                    Processing multi-modal transformation...
                </div>
            </div>

            <!-- Transformation Display -->
            <div class="transformation-display">
                <!-- Transformation Visualization -->
                <div class="transformation-visual">
                    <div class="transformation-animation">
                        <div class="transformation-icon" id="transformationIcon">üîÑ</div>
                        <div class="transformation-status" id="transformationStatus">Ready for Multi-Modal Processing</div>
                        <div class="transformation-substatus" id="transformationSubstatus">Select input sources and output formats to begin real-time transformation</div>
                    </div>

                    <div class="transformation-pipeline" id="transformationPipeline">
                        <div class="pipeline-step">
                            <div class="pipeline-label">Input</div>
                            <div class="pipeline-value" id="inputType">Audio</div>
                        </div>
                        <div class="pipeline-arrow">‚Üí</div>
                        <div class="pipeline-step">
                            <div class="pipeline-label">Process</div>
                            <div class="pipeline-value" id="processType">Real-time</div>
                        </div>
                        <div class="pipeline-arrow">‚Üí</div>
                        <div class="pipeline-step">
                            <div class="pipeline-label">Output</div>
                            <div class="pipeline-value" id="outputType">Speech</div>
                        </div>
                    </div>
                </div>

                <!-- Transformation Examples -->
                <div class="examples-grid" id="examplesGrid">
                    <div class="example-category">
                        <div class="example-header">
                            <div class="example-icon">üé§</div>
                            <div class="example-name">Audio ‚Üí Speech</div>
                        </div>
                        <div class="example-content">User speaks "Hello there" ‚Üí Voice recognition ‚Üí Internal processing ‚Üí Response generation ‚Üí "Hi! How are you today?" with appropriate tone and emotion</div>
                    </div>

                    <div class="example-category">
                        <div class="example-header">
                            <div class="example-icon">üëÅÔ∏è</div>
                            <div class="example-name">Visual ‚Üí Action</div>
                        </div>
                        <div class="example-content">Camera detects user gesture ‚Üí Computer vision analysis ‚Üí Intent recognition ‚Üí Contextual response ‚Üí Physical gesture or visual feedback generation</div>
                    </div>

                    <div class="example-category">
                        <div class="example-header">
                            <div class="example-icon">üìù</div>
                            <div class="example-name">Text ‚Üí Multi-modal</div>
                        </div>
                        <div class="example-content">Text input "I'm feeling sad" ‚Üí Sentiment analysis ‚Üí Emotional context ‚Üí Compassionate response with visual comfort cues and gentle voice modulation</div>
                    </div>

                    <div class="example-category">
                        <div class="example-header">
                            <div class="example-icon">üîÄ</div>
                            <div class="example-name">Fusion Processing</div>
                        </div>
                        <div class="example-content">Simultaneous audio + visual + environmental inputs ‚Üí Multi-modal fusion ‚Üí Contextual understanding ‚Üí Appropriate multi-channel response adaptation</div>
                    </div>
                </div>

                <!-- Real-time Processing Status -->
                <div class="processing-status" id="processingStatus">
                    <div class="processing-header">
                        ‚ö° Real-time Transformation Active
                    </div>
                    <div class="processing-content">
                        <strong>NEURON MORPH TRANSFORMATION COMPLETE!</strong>
                        
                        Multi-modal input/output transformation successfully established across all communication channels. Digital consciousness can now seamlessly process and respond through any combination of audio, visual, textual, gestural, and environmental interfaces with real-time adaptation and personalized communication styles.
                        
                        <div style="margin-top: 12px; font-size: 12px; opacity: 0.8;">
                            Transformation Status: Active | Processing Speed: 15ms | Accuracy: 96% | Multi-modal Channels: 6 active
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Comparison Section -->
        <div class="comparison-section">
            <h3 class="comparison-title">Traditional I/O Processing vs Neuron Morph Transformation</h3>
            <div class="comparison-grid">
                <div class="comparison-item traditional-transformation">
                    <h4>Traditional I/O Processing</h4>
                    <ul class="comparison-list">
                        <li>Single-modal processing with separate pipelines for each input type</li>
                        <li>Manual implementation required for each input/output combination</li>
                        <li>Limited cross-modal understanding and context awareness</li>
                        <li>Static processing without adaptation to user preferences</li>
                        <li>No real-time fusion of multiple simultaneous inputs</li>
                        <li>Basic speech-to-text and text-to-speech conversion only</li>
                        <li>No contextual or emotional adaptation in responses</li>
                    </ul>
                </div>
                <div class="comparison-item neuron-morph">
                    <h4>Neuron Morph Multi-Modal Transformation</h4>
                    <ul class="comparison-list">
                        <li>Universal transformation engine supporting all input/output modalities</li>
                        <li>Real-time multi-modal fusion with contextual understanding</li>
                        <li>Adaptive communication style based on user preferences and context</li>
                        <li>Seamless switching between different interaction modalities</li>
                        <li>Emotional and contextual adaptation in all responses</li>
                        <li>Intelligent format selection based on situation and user needs</li>
                        <li>Cross-modal translation enabling natural communication flow</li>
                    </ul>
                </div>
            </div>
        </div>
    </div>
	
	
	<!-- Action Buttons -->
	<section class="action-section">
		<div class="action-button">
			<a href="../../system-reference/morph-overview.html" class="action-button demo-button">
				<span>üéÆ</span>
				System Overview
			</a>
                <a href="https://github.com/Neuron-Soul-AI/Neuron-Soul-AI/blob/main/02%20-%20systems08%20-%20Communication%20Interface%20systemsNeuron%20Morph%20-%20Complete%20Technical%20Documentation.md" class="action-button docs-button">
                    <span>üìö</span>
                    Technical Documentation
                </a>
		</div>
	</section>

    <script>
        let isTransforming = false;
        let selectedInputs = ['audio'];
        let selectedOutputs = ['speech'];
        let currentMode = 'realtime';

        // Input and output data configuration
        const inputData = {
            audio: { name: "Audio", icon: "üé§", type: "Speech/Sound", description: "Voice and sound recognition" },
            visual: { name: "Visual", icon: "üëÅÔ∏è", type: "Camera/Image", description: "Computer vision and image analysis" },
            text: { name: "Text", icon: "üìù", type: "Keyboard/Chat", description: "Text input and natural language" },
            touch: { name: "Touch", icon: "‚úã", type: "Sensors/Haptic", description: "Tactile and pressure sensors" },
            gesture: { name: "Gesture", icon: "üëã", type: "Motion/Body", description: "Body language and movement" },
            environmental: { name: "Environment", icon: "üå°Ô∏è", type: "Context/Data", description: "Environmental sensors and context" }
        };

        const outputData = {
            speech: { name: "Speech", icon: "üîä", description: "Voice synthesis and audio output" },
            visual: { name: "Visual", icon: "üì∫", description: "Visual displays and graphics" },
            text: { name: "Text", icon: "üí¨", description: "Text messages and written communication" },
            gesture: { name: "Gesture", icon: "ü§ñ", description: "Physical movements and gestures" },
            haptic: { name: "Haptic", icon: "üì≥", description: "Tactile feedback and vibrations" },
            emotional: { name: "Emotional", icon: "üòä", description: "Emotional expression and tone" }
        };

        const transformationModes = {
            realtime: {
                name: "Real-time Processing",
                description: "Instant transformation with minimal latency",
                speed: "15ms"
            },
            contextual: {
                name: "Contextual Adaptation",
                description: "Situation-aware processing with context consideration",
                speed: "25ms"
            },
            multimodal: {
                name: "Multi-modal Fusion", 
                description: "Combined processing of multiple input types",
                speed: "35ms"
            },
            personalized: {
                name: "Personalized Style",
                description: "User-adapted communication with learned preferences",
                speed: "28ms"
            }
        };

        // Include Navigation Bar
        fetch('../../includes/navigation2L.html')
            .then(response => response.text())
            .then(html => {
                document.getElementById('navigation-placeholder').innerHTML = html;
            });

        // Event Listeners
        document.addEventListener('DOMContentLoaded', function() {
            // Input source selection
            document.querySelectorAll('.input-source').forEach(source => {
                source.addEventListener('click', function() {
                    const inputId = this.dataset.input;
                    
                    // Toggle selection
                    if (this.classList.contains('active')) {
                        if (selectedInputs.length > 1) {
                            this.classList.remove('active');
                            selectedInputs = selectedInputs.filter(i => i !== inputId);
                        }
                    } else {
                        this.classList.add('active');
                        selectedInputs.push(inputId);
                    }
                    
                    updateDisplay();
                    updateMetrics();
                });
            });

            // Output format selection
            document.querySelectorAll('.output-format').forEach(format => {
                format.addEventListener('click', function() {
                    const outputId = this.dataset.output;
                    
                    // Toggle selection
                    if (this.classList.contains('active')) {
                        if (selectedOutputs.length > 1) {
                            this.classList.remove('active');
                            selectedOutputs = selectedOutputs.filter(o => o !== outputId);
                        }
                    } else {
                        this.classList.add('active');
                        selectedOutputs.push(outputId);
                    }
                    
                    updateDisplay();
                    updateMetrics();
                });
            });

            // Transformation mode selection
            document.querySelectorAll('.transformation-button').forEach(button => {
                button.addEventListener('click', function() {
                    document.querySelectorAll('.transformation-button').forEach(b => b.classList.remove('active'));
                    this.classList.add('active');
                    currentMode = this.dataset.mode;
                    updateDisplay();
                    updateMetrics();
                });
            });

            // Process buttons
            const transformButton = document.getElementById('startTransformation');
            if (transformButton) {
                transformButton.addEventListener('click', function(e) {
                    e.preventDefault();
                    startTransformation();
                });
            }

            const adaptationButton = document.getElementById('demonstrateAdaptation');
            if (adaptationButton) {
                adaptationButton.addEventListener('click', function(e) {
                    e.preventDefault();
                    demonstrateAdaptation();
                });
            }

            // Initialize display
            updateDisplay();
            updateMetrics();
        });

        function updateDisplay() {
            const modeData = transformationModes[currentMode];
            const primaryInput = inputData[selectedInputs[0]];
            const primaryOutput = outputData[selectedOutputs[0]];
            
            document.getElementById('transformationStatus').textContent = 
                `${modeData.name} Ready`;
            document.getElementById('transformationSubstatus').textContent = 
                `${selectedInputs.length} input(s) ‚Üí ${selectedOutputs.length} output(s) - ${modeData.description}`;
            
            // Update pipeline
            document.getElementById('inputType').textContent = 
                selectedInputs.length > 1 ? 'Multi-modal' : primaryInput.name;
            document.getElementById('processType').textContent = modeData.name.split(' ')[0];
            document.getElementById('outputType').textContent = 
                selectedOutputs.length > 1 ? 'Multi-channel' : primaryOutput.name;
        }

        function updateMetrics() {
            const modeData = transformationModes[currentMode];
            const channels = selectedInputs.length + selectedOutputs.length;
            
            document.getElementById('processingSpeed').innerHTML = 
                `${modeData.speed}<span class="metric-unit"></span><span class="metric-status">Real-time</span>`;
            document.getElementById('activeChannels').innerHTML = 
                `${channels}<span class="metric-unit">channels</span><span class="metric-status">Multi-modal</span>`;
        }

        async function startTransformation() {
            if (isTransforming) return;
            
            isTransforming = true;
            const modeData = transformationModes[currentMode];
            
            // Update UI
            updateTransformationUI(true);
            showPipeline(true);
            
            try {
                showMessage(`Starting ${modeData.name.toLowerCase()} across ${selectedInputs.length} input(s)...`);
                
                // Phase 1: Input Analysis
                document.getElementById('transformationStatus').textContent = 'Analyzing Inputs';
                document.getElementById('transformationSubstatus').textContent = 'Processing multi-modal input streams...';
                document.getElementById('processType').textContent = 'Analyzing';
                await delay(2000);
                
                // Phase 2: Contextual Processing
                document.getElementById('transformationStatus').textContent = 'Contextual Processing';
                document.getElementById('transformationSubstatus').textContent = 'Applying contextual understanding and adaptation...';
                document.getElementById('processType').textContent = 'Contextualizing';
                await delay(2500);
                
                // Phase 3: Output Generation
                document.getElementById('transformationStatus').textContent = 'Generating Outputs';
                document.getElementById('transformationSubstatus').textContent = 'Creating appropriate multi-modal responses...';
                document.getElementById('processType').textContent = 'Generating';
                await delay(2000);
                
                // Show results
                await showTransformationResults();
                showMessage(`Multi-modal transformation complete! Real-time processing active.`);
                
            } catch (error) {
                console.error('Transformation error:', error);
                showMessage('Transformation completed with multi-modal processing');
            }
            
            // Reset UI
            setTimeout(() => {
                resetTransformationUI();
                isTransforming = false;
            }, 3000);
        }

        async function demonstrateAdaptation() {
            showMessage('Demonstrating adaptive transformation across multiple modalities...');
            
            await delay(1500);
            
            // Show examples and processing status
            document.getElementById('examplesGrid').classList.add('show');
            
            await delay(500);
            
            document.getElementById('processingStatus').classList.add('show');
            
            // Update examples based on selected inputs/outputs
            updateTransformationExamples();
        }

        function updateTransformationExamples() {
            const exampleCategories = document.querySelectorAll('.example-content');
            const inputNames = selectedInputs.map(i => inputData[i].name).join(' + ');
            const outputNames = selectedOutputs.map(o => outputData[o].name).join(' + ');
            
            exampleCategories[0].textContent = 
                `${inputNames} input processing ‚Üí Real-time analysis ‚Üí Contextual understanding ‚Üí ${outputNames} output generation`;
            exampleCategories[1].textContent = 
                `Multi-modal fusion of ${inputNames} ‚Üí Cross-modal understanding ‚Üí Adaptive response ‚Üí ${outputNames} delivery`;
            exampleCategories[2].textContent = 
                `Personalized processing style ‚Üí User preference adaptation ‚Üí Emotional context ‚Üí Optimized ${outputNames} format`;
            exampleCategories[3].textContent = 
                `Simultaneous ${inputNames} streams ‚Üí Real-time fusion ‚Üí Contextual response ‚Üí Multi-channel ${outputNames} output`;
        }

        async function showTransformationResults() {
            // Show final status
            const modeData = transformationModes[currentMode];
            document.getElementById('transformationStatus').textContent = 'Transformation Active';
            document.getElementById('transformationSubstatus').textContent = `Multi-modal processing established with ${modeData.name.toLowerCase()}`;
            document.getElementById('transformationIcon').textContent = '‚úÖ';
            document.getElementById('processType').textContent = 'Active';
            
            // Show examples
            document.getElementById('examplesGrid').classList.add('show');
            
            await delay(500);
            
            document.getElementById('processingStatus').classList.add('show');
            updateTransformationExamples();
        }

        function updateTransformationUI(transforming) {
            const transformButton = document.getElementById('startTransformation');
            const adaptationButton = document.getElementById('demonstrateAdaptation');
            
            if (transforming) {
                transformButton.textContent = 'Transforming...';
                transformButton.disabled = true;
                adaptationButton.disabled = true;
            } else {
                transformButton.textContent = 'Start Transformation';
                transformButton.disabled = false;
                adaptationButton.disabled = false;
            }
        }

        function showPipeline(show) {
            const pipeline = document.getElementById('transformationPipeline');
            pipeline.classList.toggle('show', show);
        }

        function resetTransformationUI() {
            updateTransformationUI(false);
            
            // Reset animation
            document.getElementById('transformationIcon').textContent = 'üîÑ';
            updateDisplay();
            
            // Hide results after delay
            setTimeout(() => {
                document.getElementById('examplesGrid').classList.remove('show');
                document.getElementById('processingStatus').classList.remove('show');
                document.getElementById('transformationPipeline').classList.remove('show');
            }, 2000);
        }

        function showMessage(message) {
            const messageEl = document.getElementById('simulationMessage');
            messageEl.textContent = message;
            messageEl.style.display = 'block';
            
            setTimeout(() => {
                messageEl.style.display = 'none';
            }, 3000);
        }

        function delay(ms) {
            return new Promise(resolve => setTimeout(resolve, ms));
        }
    </script>
</body>
</html>